{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martush/martush_notebooks/blob/develop/Char_Level_Language_Model_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AvUjvsYPlX2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "22EnvimylhXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6694af-2cc3-4494-b10b-86b5ccc90500"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#words = open('gdrive/My Drive/names.txt', 'r').read().splitlines()\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2754BNSrt63H",
        "outputId": "b4c3d93e-a7d8-477f-e32d-024b98dcefd6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrdUxHrt9Cs",
        "outputId": "7f2d04f2-5740-4fec-9d3b-4bea21192661"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build vocabulary of all chars and mapping to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYfSxHRyt-r5",
        "outputId": "e39e9888-e772-4f4e-9d20-16edf2b59605"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "block_size = 3 #context length - how many input chars to predict next\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  print(f'Context: {context}')\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "    context = context[1:] + [ix] #crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNvQZW0ugw0",
        "outputId": "506fb5b1-cae7-4f7e-f85f-34c5f84efbd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "Context: [0, 0, 0]\n",
            "... ----> e\n",
            "..e ----> m\n",
            ".em ----> m\n",
            "emm ----> a\n",
            "mma ----> .\n",
            "olivia\n",
            "Context: [0, 0, 0]\n",
            "... ----> o\n",
            "..o ----> l\n",
            ".ol ----> i\n",
            "oli ----> v\n",
            "liv ----> i\n",
            "ivi ----> a\n",
            "via ----> .\n",
            "ava\n",
            "Context: [0, 0, 0]\n",
            "... ----> a\n",
            "..a ----> v\n",
            ".av ----> a\n",
            "ava ----> .\n",
            "isabella\n",
            "Context: [0, 0, 0]\n",
            "... ----> i\n",
            "..i ----> s\n",
            ".is ----> a\n",
            "isa ----> b\n",
            "sab ----> e\n",
            "abe ----> l\n",
            "bel ----> l\n",
            "ell ----> a\n",
            "lla ----> .\n",
            "sophia\n",
            "Context: [0, 0, 0]\n",
            "... ----> s\n",
            "..s ----> o\n",
            ".so ----> p\n",
            "sop ----> h\n",
            "oph ----> i\n",
            "phi ----> a\n",
            "hia ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8kFSxeUwDmf",
        "outputId": "f0ecab81-f122-4baf-f7f3-326e742f5e64"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueN4rrJMxmZL",
        "outputId": "e0f773aa-98b5-46c7-acd9-42341934c6e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct embeddings"
      ],
      "metadata": {
        "id": "PhbA9f5042Oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to create the lookup table. In the reference paper they have 17,000 words crammed into 30 dimensions. We only have 27 characters and we can start  with only 2 dimensions."
      ],
      "metadata": {
        "id": "3KZfkXa2xxr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "GK1CPdV4yUtC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check a single embedding\n",
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqQzGYWtyGIH",
        "outputId": "b0fc2bc8-c253-41f0-b902-7ea84b4ee685"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8768, 0.5885])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5,6,7,7,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mimn1w_-vAip",
        "outputId": "8bc2ad1e-0027-4841-877c-0c22290d5222"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8768,  0.5885],\n",
              "        [ 1.1330, -0.8091],\n",
              "        [ 1.0338, -0.6338],\n",
              "        [ 1.0338, -0.6338],\n",
              "        [ 1.0338, -0.6338]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also index with multiple dimension\n",
        "C[X]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljbHvyg9vVne",
        "outputId": "f4814bb0-d80b-4486-ca9d-aee49ca8b105"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [ 0.8768,  0.5885]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [ 0.8768,  0.5885],\n",
              "         [-1.3930, -0.7881]],\n",
              "\n",
              "        [[ 0.8768,  0.5885],\n",
              "         [-1.3930, -0.7881],\n",
              "         [-1.3930, -0.7881]],\n",
              "\n",
              "        [[-1.3930, -0.7881],\n",
              "         [-1.3930, -0.7881],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [ 0.5870, -2.7339]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [ 0.5870, -2.7339],\n",
              "         [-0.4194,  0.1204]],\n",
              "\n",
              "        [[ 0.5870, -2.7339],\n",
              "         [-0.4194,  0.1204],\n",
              "         [-0.9771,  0.7770]],\n",
              "\n",
              "        [[-0.4194,  0.1204],\n",
              "         [-0.9771,  0.7770],\n",
              "         [ 0.7082, -1.2748]],\n",
              "\n",
              "        [[-0.9771,  0.7770],\n",
              "         [ 0.7082, -1.2748],\n",
              "         [-0.9771,  0.7770]],\n",
              "\n",
              "        [[ 0.7082, -1.2748],\n",
              "         [-0.9771,  0.7770],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.9813, -1.9754],\n",
              "         [ 0.7082, -1.2748]],\n",
              "\n",
              "        [[-0.9813, -1.9754],\n",
              "         [ 0.7082, -1.2748],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.9771,  0.7770]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.9771,  0.7770],\n",
              "         [ 1.6542, -0.6822]],\n",
              "\n",
              "        [[-0.9771,  0.7770],\n",
              "         [ 1.6542, -0.6822],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[ 1.6542, -0.6822],\n",
              "         [-0.9813, -1.9754],\n",
              "         [-0.1121, -0.9897]],\n",
              "\n",
              "        [[-0.9813, -1.9754],\n",
              "         [-0.1121, -0.9897],\n",
              "         [ 0.8768,  0.5885]],\n",
              "\n",
              "        [[-0.1121, -0.9897],\n",
              "         [ 0.8768,  0.5885],\n",
              "         [-0.4194,  0.1204]],\n",
              "\n",
              "        [[ 0.8768,  0.5885],\n",
              "         [-0.4194,  0.1204],\n",
              "         [-0.4194,  0.1204]],\n",
              "\n",
              "        [[-0.4194,  0.1204],\n",
              "         [-0.4194,  0.1204],\n",
              "         [-0.9813, -1.9754]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [-0.8678, -0.5760],\n",
              "         [ 1.6542, -0.6822]],\n",
              "\n",
              "        [[-0.8678, -0.5760],\n",
              "         [ 1.6542, -0.6822],\n",
              "         [ 0.5870, -2.7339]],\n",
              "\n",
              "        [[ 1.6542, -0.6822],\n",
              "         [ 0.5870, -2.7339],\n",
              "         [-0.5365,  1.2598]],\n",
              "\n",
              "        [[ 0.5870, -2.7339],\n",
              "         [-0.5365,  1.2598],\n",
              "         [-0.0647,  0.4767]],\n",
              "\n",
              "        [[-0.5365,  1.2598],\n",
              "         [-0.0647,  0.4767],\n",
              "         [-0.9771,  0.7770]],\n",
              "\n",
              "        [[-0.0647,  0.4767],\n",
              "         [-0.9771,  0.7770],\n",
              "         [-0.9813, -1.9754]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spElmstEvfav",
        "outputId": "cb86e15c-aa48-4c68-90fa-ac1c4987d119"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[13,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5m2N0WtvuNn",
        "outputId": "8e551cb2-1e3a-4ec2-a256-08ad45dbe9b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X][13,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2N0w4dSvxVE",
        "outputId": "a2802353-8559-4cb9-cbc6-9ec7d662ec46"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9813, -1.9754])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljz_e6jGvuQF",
        "outputId": "a857d1de-95d3-44f4-834f-0e67a0e99f9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9813, -1.9754])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = F.one_hot(torch.tensor(5), num_classes=27)\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTBFQ2d8yCut",
        "outputId": "4855eede-20d8-48c5-83cd-7048a1b6fd09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot are int64 and C is float - pytorch doesn't know how to multiply them\n",
        "encoded @ C"
      ],
      "metadata": {
        "id": "khbczIlCyl3n",
        "outputId": "5246ebf6-53a7-4f72-9f77-5086c7622d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected m1 and m2 to have the same dtype, but got: long int != float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2789858489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one-hot are int64 and C is float - pytorch doesn't know how to multiply them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: long int != float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identical output\n",
        "encoded.float() @ C"
      ],
      "metadata": {
        "id": "zEH5CZ6oy9BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 approaches with identical results. Will simply index (C[5]) since much faster"
      ],
      "metadata": {
        "id": "8aslyUHWzUkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch indexing is quite flexible and powerful\n",
        "# We have a X with size [32, 3] which we want to embed\n",
        "# We can index 3 things at the same time\n",
        "C[[5,6,7]]"
      ],
      "metadata": {
        "id": "tmuYmPYUza5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our embedding\n",
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dqcoixwwoxu",
        "outputId": "b8047247-610f-49a0-a721-89505a5f1c89"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the hidden layer"
      ],
      "metadata": {
        "id": "nNIhIWNxw5wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.Size([32, 3, 2])\n",
        "# Inputs: 3 x 2 - 3 two-dimensional embeddings\n",
        "# Outputs we pick - pick 100 neurons\n",
        "W1 = torch.randn((6, 100))\n",
        "# biases - initialized randomly, need 100 of them\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "XmhOPsZ8wo17"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normally we'd take the input and multiply it by the weights\n",
        "emb @ W1 + b1\n",
        "# Problem is the embeddings are stacked up in the dimensions in the input tensor - 32 x 3 x 1 can't multiply by 6 x 100\n",
        "# We need to concatenate the inputs"
      ],
      "metadata": {
        "id": "tQQDIXuqwo7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are multiple ways to concatenate the dimensions."
      ],
      "metadata": {
        "id": "mQGSdnP50zqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First way - use torch.concat\n",
        "emb[:, 0, :].shape\n",
        "# These are the embeddings of the first word"
      ],
      "metadata": {
        "id": "CSYggas805nQ",
        "outputId": "54de11c4-6e65-4328-c452-dbd946d0547a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the dimensions we want to concatenate\n",
        "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
      ],
      "metadata": {
        "id": "3mckx_uE1QWT",
        "outputId": "d9d901f2-60e3-488b-9a03-e03d15232b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The above way is not scalable since directly indexing into the 3 dimensions - unbind (removes a tensor dimension and returns slices of it)\n",
        "len(torch.unbind(emb, 1))\n",
        "# exactly equal to the list above"
      ],
      "metadata": {
        "id": "FK-nKf7d1pB_",
        "outputId": "4ca5aaba-08ec-4ab5-fbee-6eb15e8b2013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is inefficient because it creates all kinds of new memory - 2 tensors cannot be manipulated like that without new memory being created\n",
        "torch.cat(torch.unbind(emb, 1), 1).shape"
      ],
      "metadata": {
        "id": "EQmt8Kp72TWP",
        "outputId": "a9baaf4b-3f0e-4802-a5a5-0451a91091ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Better way\n",
        "a = torch.arange(18)\n",
        "a"
      ],
      "metadata": {
        "id": "N_voGur82f0w",
        "outputId": "0243bee5-6658-4f26-bec7-66ea2572c69b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "id": "FGEzQ6d32kEv",
        "outputId": "76bed3e8-b110-42df-9266-bed9488643bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(9, 2)"
      ],
      "metadata": {
        "id": "mQhhcuMZ2lS8",
        "outputId": "f10dcf4e-ebb7-4e24-dc7b-9e4666845bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  3],\n",
              "        [ 4,  5],\n",
              "        [ 6,  7],\n",
              "        [ 8,  9],\n",
              "        [10, 11],\n",
              "        [12, 13],\n",
              "        [14, 15],\n",
              "        [16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As long as the total number of elements multiply to be the number of the original vector, you can pick any dimensions.\n",
        "This is extremely efficient - each tensor has underlying storage which is just the numbers in a 1-dimensional vector.\n",
        "No memory is changed when calling .view - the underlying storage is the same, only the view of this tensor is changed -  storage offset, strides and shape"
      ],
      "metadata": {
        "id": "rriPjHEf2ow9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.storage()"
      ],
      "metadata": {
        "id": "ryvkahM823SE",
        "outputId": "4c3ceac7-dadf-4dd6-ddb7-35c11b9f4710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-214256462.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  a.storage()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0\n",
              " 1\n",
              " 2\n",
              " 3\n",
              " 4\n",
              " 5\n",
              " 6\n",
              " 7\n",
              " 8\n",
              " 9\n",
              " 10\n",
              " 11\n",
              " 12\n",
              " 13\n",
              " 14\n",
              " 15\n",
              " 16\n",
              " 17\n",
              "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "id": "JJwwsASr2882",
        "outputId": "8be0b492-e248-46b6-8d73-c34bd36c877d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32, 6)"
      ],
      "metadata": {
        "id": "pzIsaSD03ZoO",
        "outputId": "57639e8c-b7bd-42d1-b061-2f5e7e5701d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8678, -0.5760, -0.8678, -0.5760, -0.8678, -0.5760],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760,  0.8768,  0.5885],\n",
              "        [-0.8678, -0.5760,  0.8768,  0.5885, -1.3930, -0.7881],\n",
              "        [ 0.8768,  0.5885, -1.3930, -0.7881, -1.3930, -0.7881],\n",
              "        [-1.3930, -0.7881, -1.3930, -0.7881, -0.9813, -1.9754],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.8678, -0.5760],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760,  0.5870, -2.7339],\n",
              "        [-0.8678, -0.5760,  0.5870, -2.7339, -0.4194,  0.1204],\n",
              "        [ 0.5870, -2.7339, -0.4194,  0.1204, -0.9771,  0.7770],\n",
              "        [-0.4194,  0.1204, -0.9771,  0.7770,  0.7082, -1.2748],\n",
              "        [-0.9771,  0.7770,  0.7082, -1.2748, -0.9771,  0.7770],\n",
              "        [ 0.7082, -1.2748, -0.9771,  0.7770, -0.9813, -1.9754],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.8678, -0.5760],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.9813, -1.9754],\n",
              "        [-0.8678, -0.5760, -0.9813, -1.9754,  0.7082, -1.2748],\n",
              "        [-0.9813, -1.9754,  0.7082, -1.2748, -0.9813, -1.9754],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.8678, -0.5760],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.9771,  0.7770],\n",
              "        [-0.8678, -0.5760, -0.9771,  0.7770,  1.6542, -0.6822],\n",
              "        [-0.9771,  0.7770,  1.6542, -0.6822, -0.9813, -1.9754],\n",
              "        [ 1.6542, -0.6822, -0.9813, -1.9754, -0.1121, -0.9897],\n",
              "        [-0.9813, -1.9754, -0.1121, -0.9897,  0.8768,  0.5885],\n",
              "        [-0.1121, -0.9897,  0.8768,  0.5885, -0.4194,  0.1204],\n",
              "        [ 0.8768,  0.5885, -0.4194,  0.1204, -0.4194,  0.1204],\n",
              "        [-0.4194,  0.1204, -0.4194,  0.1204, -0.9813, -1.9754],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760, -0.8678, -0.5760],\n",
              "        [-0.8678, -0.5760, -0.8678, -0.5760,  1.6542, -0.6822],\n",
              "        [-0.8678, -0.5760,  1.6542, -0.6822,  0.5870, -2.7339],\n",
              "        [ 1.6542, -0.6822,  0.5870, -2.7339, -0.5365,  1.2598],\n",
              "        [ 0.5870, -2.7339, -0.5365,  1.2598, -0.0647,  0.4767],\n",
              "        [-0.5365,  1.2598, -0.0647,  0.4767, -0.9771,  0.7770],\n",
              "        [-0.0647,  0.4767, -0.9771,  0.7770, -0.9813, -1.9754]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify result same as before\n",
        "emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1)"
      ],
      "metadata": {
        "id": "mm6nRSKN3fMo",
        "outputId": "088e9286-d72b-4f7e-b213-0f347b0432b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now multiply to create the hiden layer\n",
        "h = emb.view(32, 6) @ W1 + b1\n",
        "\n",
        "#Improve - remove harcoding of the 32\n",
        "h = emb.view(emb.shape[0], 6) @ W1 + b1\n",
        "#can also do -1 - since the number of elements needs to be the same and we have the other as 6, pytorch will derive this to be 32\n",
        "h = emb.view(-1, 6) @ W1 + b1\n",
        "# Also add tanh the whole thing\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "tuU3i_I33nzf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to be careful with the broadcasting rules for adding b1\n",
        "# We have 32, 100 added to 100\n",
        "# 32, 100\n",
        "#     100\n",
        "#pytorch will align them on the right, create  a fake dimension (1x100 row vector) and then copy vertically for every one of the 32 rows and do an element-wise addition\n",
        "# in this case the correct thing will be happening"
      ],
      "metadata": {
        "id": "e-cU7KNH5J1e"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape\n",
        "# 32 x 100: the 100 activations for our 32 examples"
      ],
      "metadata": {
        "id": "J6c55Q4849Xt",
        "outputId": "31d74ae4-44f9-4e7e-d31c-5faa0d4fdf2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Layer"
      ],
      "metadata": {
        "id": "9LP1q67x5j8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is 100 (outputs from hidden layer), outputs are 27  (the 27 characters)\n",
        "W2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "EAfFK3Qt5nax"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "2nEEaOLm5xjS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "id": "hErZ055R5xmp",
        "outputId": "2e490997-1c83-4d08-e5f9-710e8bd3b574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "f6CRXMdD54rb",
        "outputId": "cd25e1d3-91aa-4589-eac3-b381fbac2806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.1836e+00, -7.5340e-01, -1.4372e+00,  6.6722e+00, -6.7186e+00,\n",
              "          2.0786e+00, -5.9823e+00,  9.3230e+00, -1.7241e+01, -7.8906e+00,\n",
              "          2.9034e+00, -7.1685e+00, -2.4494e+00,  2.4386e+00, -1.4416e+00,\n",
              "         -1.0815e+01,  1.1374e+01, -1.0126e+01,  1.1194e+01,  3.0792e+00,\n",
              "          5.8258e+00,  1.0673e+01,  3.8797e+00,  7.6634e+00, -3.5406e+00,\n",
              "         -1.4204e+00, -7.2076e+00],\n",
              "        [-2.3593e+00, -5.2011e+00,  3.5675e+00,  9.2174e+00, -3.6281e+00,\n",
              "         -5.4712e+00,  9.2209e-01, -2.4453e+00, -1.5070e+01,  1.0010e+00,\n",
              "          8.6779e+00, -7.1191e+00, -2.4086e+00,  4.5717e+00, -8.4149e-01,\n",
              "         -3.7803e+00,  6.1163e+00, -1.4999e+00, -2.7804e+00,  6.0377e+00,\n",
              "          5.5989e+00,  1.4721e+01,  1.0056e+01,  1.0892e+01,  6.2097e+00,\n",
              "         -5.3787e+00, -6.6482e+00],\n",
              "        [ 2.9832e-01, -2.0079e+00, -5.1163e-01,  9.4941e+00,  2.0517e+00,\n",
              "          7.3904e+00,  1.0407e+01,  3.2891e+00,  1.2824e+01,  3.2527e+00,\n",
              "          9.1522e+00, -6.4659e+00,  3.6631e-01, -1.9824e+00,  5.7035e+00,\n",
              "          5.5375e+00,  7.9120e+00, -1.4316e+01,  2.4050e+01, -1.3616e+01,\n",
              "          1.0216e+01,  9.4760e+00, -1.4382e+01, -1.8459e+01, -8.7289e+00,\n",
              "          1.8971e+00,  6.2214e+00],\n",
              "        [-1.0811e+01,  6.5373e+00,  4.5240e+00,  2.3273e+00, -1.7380e+01,\n",
              "          2.7657e+00, -8.1892e+00,  1.5534e+01, -8.8293e+00, -1.5083e+01,\n",
              "          3.3524e-01, -3.7251e+00, -9.0708e+00, -1.2770e+01, -4.8195e+00,\n",
              "         -1.3337e+01, -5.8340e+00, -4.7807e+00,  5.1919e+00,  6.0180e+00,\n",
              "         -6.5225e+00, -3.8329e-01,  5.4973e+00,  8.8254e+00, -1.4528e+00,\n",
              "          3.6427e+00, -1.2027e+01],\n",
              "        [-1.1228e+01, -3.5932e+00, -8.9925e-01,  4.2978e+00, -1.6072e+00,\n",
              "          2.8813e+00, -6.2542e+00,  1.2254e+01, -1.8956e+01, -1.0439e+01,\n",
              "          3.4596e+00, -8.2150e+00, -7.1205e+00,  3.4145e+00, -2.0703e+00,\n",
              "         -1.1876e+01,  1.2966e+01, -9.2893e+00,  1.1749e+01, -3.4557e+00,\n",
              "          6.8669e+00,  1.3901e+01,  3.0116e+00,  1.0968e+01, -1.7144e+00,\n",
              "         -8.2824e-01, -6.8504e+00],\n",
              "        [-5.1836e+00, -7.5340e-01, -1.4372e+00,  6.6722e+00, -6.7186e+00,\n",
              "          2.0786e+00, -5.9823e+00,  9.3230e+00, -1.7241e+01, -7.8906e+00,\n",
              "          2.9034e+00, -7.1685e+00, -2.4494e+00,  2.4386e+00, -1.4416e+00,\n",
              "         -1.0815e+01,  1.1374e+01, -1.0126e+01,  1.1194e+01,  3.0792e+00,\n",
              "          5.8258e+00,  1.0673e+01,  3.8797e+00,  7.6634e+00, -3.5406e+00,\n",
              "         -1.4204e+00, -7.2076e+00],\n",
              "        [-8.3697e+00, -3.2352e+00,  1.3656e+00,  1.2770e+00,  1.5584e+00,\n",
              "         -1.8331e+00, -1.1243e+01,  8.7762e+00, -1.2132e+01, -1.2726e+01,\n",
              "         -5.0633e+00, -1.5448e+00, -1.6524e+01,  9.3062e+00,  9.7161e+00,\n",
              "         -3.2928e+00,  1.6072e+00,  3.7239e+00,  4.3868e-01, -1.5880e+00,\n",
              "          6.6484e+00,  8.0220e+00,  7.8126e+00,  8.4741e+00, -6.3312e+00,\n",
              "         -2.4136e+00, -3.3975e+00],\n",
              "        [-1.1666e+01,  4.5794e+00,  7.8809e+00,  1.0995e+01, -5.0873e-01,\n",
              "         -2.5667e+00,  6.6054e-01, -6.2585e+00, -9.9381e+00,  4.3106e+00,\n",
              "         -9.8364e+00,  5.6121e+00,  1.6969e+01, -1.6559e+01, -1.0700e+01,\n",
              "         -7.8065e+00, -1.7192e+00, -1.4886e+01,  2.1467e+00,  9.2858e-01,\n",
              "          7.5379e-01,  9.0007e+00,  4.9770e+00,  4.4333e-01, -7.3565e+00,\n",
              "         -4.4497e+00,  1.4069e+00],\n",
              "        [-1.2931e+01,  3.4593e-02, -8.6985e-01,  2.2240e+01, -2.1026e+01,\n",
              "          7.2698e+00,  1.1212e+01,  9.4007e+00,  6.6855e+00,  1.6107e-01,\n",
              "          1.8773e+01, -3.2109e+00,  1.0469e+01, -6.7877e+00,  2.5245e-01,\n",
              "          2.0652e+00,  9.9300e+00, -2.1019e+01,  5.8919e+00,  1.4281e+00,\n",
              "          1.2800e+01, -5.2759e-01, -4.1900e+00, -3.7097e+00,  8.6350e+00,\n",
              "         -1.6622e+01, -1.0921e+01],\n",
              "        [-6.7128e+00,  3.9094e+00, -6.7767e+00, -3.9228e+00, -2.8247e+00,\n",
              "         -3.1229e+00, -1.1006e+01,  5.9101e+00, -8.3280e+00, -1.4829e+01,\n",
              "          6.0655e+00, -5.2075e+00, -2.3598e+01,  9.5498e+00,  1.1964e+01,\n",
              "         -1.0872e+00,  3.9362e+00,  9.9709e+00, -4.7866e+00, -1.7234e-01,\n",
              "          6.0067e+00,  2.5867e+00,  4.2232e+00,  3.0809e+00,  1.3757e+00,\n",
              "          2.9624e+00, -2.3909e+00],\n",
              "        [ 3.8263e+00,  3.0975e+00,  5.0172e+00,  5.6281e+00,  4.0748e+00,\n",
              "         -1.1482e+00, -7.9017e-01, -1.0497e+01, -9.2029e+00,  4.0482e+00,\n",
              "         -4.8564e+00, -1.0349e+01,  1.1026e+01, -1.7372e+01, -5.4811e+00,\n",
              "         -8.4407e+00, -1.7726e+00, -1.4140e+01,  1.4548e+01, -1.7802e+00,\n",
              "         -4.1707e+00,  6.4452e+00,  2.3883e-01, -1.3352e+01, -1.2139e+01,\n",
              "         -2.3822e+00,  6.1033e+00],\n",
              "        [-5.5702e+00, -1.1302e-01,  1.5544e+00,  5.3314e+00, -1.3429e+01,\n",
              "          4.5309e+00, -1.7830e+00,  1.1577e+01,  2.1642e+00, -9.6863e+00,\n",
              "          5.9993e+00, -1.0006e+01, -6.6489e+00, -8.4758e+00,  2.4073e+00,\n",
              "         -2.4261e+00,  3.8511e-01, -5.5751e+00,  6.0684e+00, -4.5841e+00,\n",
              "          2.3171e+00,  5.0627e+00, -8.3200e+00, -4.5440e+00, -4.1098e+00,\n",
              "          4.4290e+00, -1.0078e+01],\n",
              "        [-5.1836e+00, -7.5340e-01, -1.4372e+00,  6.6722e+00, -6.7186e+00,\n",
              "          2.0786e+00, -5.9823e+00,  9.3230e+00, -1.7241e+01, -7.8906e+00,\n",
              "          2.9034e+00, -7.1685e+00, -2.4494e+00,  2.4386e+00, -1.4416e+00,\n",
              "         -1.0815e+01,  1.1374e+01, -1.0126e+01,  1.1194e+01,  3.0792e+00,\n",
              "          5.8258e+00,  1.0673e+01,  3.8797e+00,  7.6634e+00, -3.5406e+00,\n",
              "         -1.4204e+00, -7.2076e+00],\n",
              "        [-1.0011e+01, -4.2215e+00, -2.5836e+00,  4.2968e+00, -1.6430e+00,\n",
              "          5.1642e+00, -5.8560e+00,  1.4218e+01, -1.3390e+01, -1.2389e+01,\n",
              "          2.6585e+00, -6.1103e+00, -8.3462e+00,  4.2944e-01, -8.7017e-01,\n",
              "         -9.0005e+00,  7.8420e+00, -7.3748e+00,  1.2993e+01, -5.7548e+00,\n",
              "          3.4773e+00,  9.9640e+00, -8.6149e-01,  7.0646e+00, -1.6000e+00,\n",
              "          9.9752e-01, -5.2050e-01],\n",
              "        [-2.6078e+00, -9.8679e-01,  3.8658e+00,  7.0462e+00,  8.9612e+00,\n",
              "         -5.5969e+00, -6.3375e+00, -4.8551e+00, -1.9184e+01, -5.6111e+00,\n",
              "         -1.0210e+01, -4.7925e+00, -2.3011e+00, -5.6467e+00, -6.1635e+00,\n",
              "         -1.1127e+01,  7.7272e+00,  3.7745e+00, -2.9924e-01, -2.5945e+00,\n",
              "          3.0061e+00,  1.1707e+01,  1.2618e+01,  1.2806e+01,  4.2597e+00,\n",
              "         -5.7805e+00, -6.1799e+00],\n",
              "        [-1.3750e+01, -1.3745e+00,  3.1887e+00,  1.0693e+01,  2.3834e+00,\n",
              "          2.8715e+00,  5.9006e-01, -1.1640e+00, -6.9099e+00, -3.7550e+00,\n",
              "         -1.5910e+01, -3.4284e+00,  2.3264e-01, -1.4133e-01,  1.8235e+00,\n",
              "         -1.0991e+00,  1.5052e+00, -1.3842e+01,  1.5937e+01, -1.2360e+01,\n",
              "          5.4363e+00,  1.3404e+01, -3.0361e+00, -4.6428e+00, -7.4098e+00,\n",
              "         -1.0446e+01,  1.9853e+00],\n",
              "        [-5.1836e+00, -7.5340e-01, -1.4372e+00,  6.6722e+00, -6.7186e+00,\n",
              "          2.0786e+00, -5.9823e+00,  9.3230e+00, -1.7241e+01, -7.8906e+00,\n",
              "          2.9034e+00, -7.1685e+00, -2.4494e+00,  2.4386e+00, -1.4416e+00,\n",
              "         -1.0815e+01,  1.1374e+01, -1.0126e+01,  1.1194e+01,  3.0792e+00,\n",
              "          5.8258e+00,  1.0673e+01,  3.8797e+00,  7.6634e+00, -3.5406e+00,\n",
              "         -1.4204e+00, -7.2076e+00],\n",
              "        [-5.4948e+00,  1.8226e+00,  4.7118e+00,  1.4560e+01, -1.0213e+01,\n",
              "          7.3760e-02, -3.8888e+00,  7.1374e+00, -1.9350e+01, -1.1879e-01,\n",
              "          1.2982e+01, -6.0086e+00,  7.2184e+00,  2.9172e-01, -1.9169e+00,\n",
              "         -4.9155e+00,  8.2465e+00, -1.3092e+01,  8.9869e+00,  1.0038e+01,\n",
              "          9.3648e+00,  6.5670e+00,  6.0461e+00,  2.9027e+00, -8.8955e-01,\n",
              "         -5.5374e+00, -5.5989e+00],\n",
              "        [-5.7066e+00, -1.7475e+00, -1.0904e+01, -3.7061e-02,  7.3566e+00,\n",
              "         -1.0069e+00, -4.6288e+00, -2.7160e+00, -1.1228e+01, -4.9354e+00,\n",
              "          1.6938e+00, -3.8382e+00, -1.7717e+01,  1.5307e+01,  7.5743e+00,\n",
              "          3.4978e+00,  4.5219e+00,  1.5659e+01, -3.1512e+00, -2.3772e+00,\n",
              "          6.6328e+00,  7.4391e+00,  5.4980e+00,  6.2126e+00,  7.5595e+00,\n",
              "         -7.5510e+00, -3.5031e+00],\n",
              "        [-9.0858e+00, -2.1313e+00, -5.0734e+00, -1.8240e+00,  8.0830e+00,\n",
              "          4.5031e-01, -6.7013e+00, -1.1651e+01,  5.5217e-01, -1.5315e+00,\n",
              "         -9.3077e+00,  6.4728e+00, -2.8664e+00, -5.3769e+00,  6.7443e+00,\n",
              "         -1.9797e+00, -5.0061e+00, -1.3633e+00,  1.7476e+01, -1.1085e+01,\n",
              "          8.5712e+00,  5.4926e+00, -1.0471e+01, -9.6847e+00, -7.8638e+00,\n",
              "          4.3173e+00,  5.6702e+00],\n",
              "        [-4.3304e+00,  7.4597e+00, -6.0897e-01,  1.3161e+01, -1.1788e+01,\n",
              "         -3.8125e+00, -1.8300e+00,  2.7459e+00, -1.0274e+01, -1.5833e+01,\n",
              "         -8.8309e+00, -4.8971e-01, -5.6066e+00, -1.7457e+01, -3.8225e+00,\n",
              "         -1.1169e+01, -4.6175e+00,  1.1518e+00,  4.1728e+00, -1.0210e+00,\n",
              "         -2.7527e+00,  4.1992e+00,  9.7660e+00,  4.3296e+00,  6.8610e+00,\n",
              "         -1.2933e+01, -7.5748e+00],\n",
              "        [-1.0592e+01, -7.4844e-01,  8.6388e+00,  2.4495e+01, -4.8286e+00,\n",
              "         -3.6316e+00,  6.1962e+00, -9.9696e+00, -7.1673e+00,  4.8378e+00,\n",
              "          8.2842e+00, -5.5896e+00,  1.0955e+01,  4.9838e+00, -8.6882e+00,\n",
              "          7.0950e+00,  1.3628e+01, -1.5831e+01,  4.2037e+00, -1.8875e+00,\n",
              "          1.1820e+01,  1.7709e+01,  3.3124e+00,  1.9214e+00,  1.1778e+01,\n",
              "         -1.2644e+01, -6.9714e+00],\n",
              "        [ 6.1803e+00, -5.6248e+00, -3.8962e+00,  9.4800e+00, -7.0629e+00,\n",
              "          9.2747e+00,  7.3993e+00, -1.3333e+00,  1.7307e+01,  7.9656e+00,\n",
              "          1.1046e+01, -9.9662e+00,  6.3481e+00, -1.4345e+00,  5.7847e+00,\n",
              "          1.1085e+01,  8.2109e+00, -1.2825e+01,  1.7692e+01, -5.5547e+00,\n",
              "          1.4662e+01, -4.5244e+00, -1.4901e+01, -1.7530e+01, -1.7629e+00,\n",
              "         -1.9645e+00,  1.5582e-01],\n",
              "        [ 1.3467e+00,  2.5691e+00, -4.1536e+00,  6.4906e+00, -1.5511e+01,\n",
              "          3.4317e+00,  2.6743e+00,  2.0429e+00,  9.1110e+00, -1.3639e+01,\n",
              "          7.8563e+00, -1.4084e+01, -3.7267e+00, -1.6078e+01, -1.7037e+00,\n",
              "         -6.0381e+00, -5.1341e+00,  2.7008e+00,  4.0811e+00, -2.8804e+00,\n",
              "         -2.9166e+00, -8.6726e+00, -7.2571e-03, -5.2920e+00, -1.0436e+00,\n",
              "         -3.3967e+00, -4.5165e+00],\n",
              "        [-2.3730e+00,  2.6170e+00, -9.3633e+00,  3.5313e+00,  8.7118e-01,\n",
              "          4.0330e+00, -9.0089e+00,  4.6593e+00, -2.0156e+00, -1.2880e+01,\n",
              "          5.9152e-01,  3.6693e+00, -9.3592e+00, -3.0030e+00,  4.5125e+00,\n",
              "         -4.9687e+00,  3.6022e-01, -3.3369e+00,  1.3184e+01, -1.0107e+01,\n",
              "          6.8004e+00,  5.0937e+00, -5.1537e+00, -3.1706e+00, -7.2861e+00,\n",
              "          1.6463e+00,  2.0240e+00],\n",
              "        [-5.1836e+00, -7.5340e-01, -1.4372e+00,  6.6722e+00, -6.7186e+00,\n",
              "          2.0786e+00, -5.9823e+00,  9.3230e+00, -1.7241e+01, -7.8906e+00,\n",
              "          2.9034e+00, -7.1685e+00, -2.4494e+00,  2.4386e+00, -1.4416e+00,\n",
              "         -1.0815e+01,  1.1374e+01, -1.0126e+01,  1.1194e+01,  3.0792e+00,\n",
              "          5.8258e+00,  1.0673e+01,  3.8797e+00,  7.6634e+00, -3.5406e+00,\n",
              "         -1.4204e+00, -7.2076e+00],\n",
              "        [-3.6606e-01, -3.3524e+00, -6.2359e+00,  2.8609e+00,  1.0425e+01,\n",
              "         -5.1638e+00, -8.2588e+00, -9.8560e+00, -1.5694e+01, -2.4613e-01,\n",
              "         -3.7458e+00,  1.3561e+00, -1.0364e+01,  7.3158e+00, -1.9486e+00,\n",
              "         -1.8360e+00,  4.6003e+00,  1.1547e+01, -2.2886e+00,  6.9181e-02,\n",
              "          3.4575e+00,  1.0764e+01,  1.4662e+01,  6.0577e+00,  5.8440e+00,\n",
              "         -9.4098e+00, -4.4414e+00],\n",
              "        [-1.1000e+01, -6.8278e+00, -8.1120e-01, -1.8386e+00,  8.0113e+00,\n",
              "          2.1309e+00, -2.3059e+00,  9.5241e-01,  5.4905e+00, -6.0045e+00,\n",
              "         -1.6503e+01,  6.7830e+00, -1.6473e+01,  8.8741e+00,  3.4434e+00,\n",
              "         -7.1766e-01, -5.5553e+00, -8.2551e-01,  7.7829e+00, -7.0572e+00,\n",
              "         -6.7514e-02,  7.0672e+00, -9.7931e+00, -7.3168e+00, -1.0995e+01,\n",
              "          7.3971e-02,  1.6389e+00],\n",
              "        [-3.7948e+00,  9.6583e+00,  1.2678e+01,  1.7948e+01, -2.2894e+01,\n",
              "         -5.4379e+00,  4.1138e+00, -7.4265e+00, -2.5986e+00,  2.4525e+00,\n",
              "         -1.0062e+01,  3.8427e+00,  5.5704e+00, -2.2056e+01, -1.1824e+01,\n",
              "         -6.4558e+00, -9.1459e+00, -2.0317e+01,  3.6182e+00,  4.2805e+00,\n",
              "          3.4233e-01,  6.4602e-01,  6.0497e+00,  1.3888e+00, -6.9595e-01,\n",
              "         -4.9005e+00, -3.1189e+00],\n",
              "        [-1.1064e+01, -2.4347e+00, -6.5337e+00,  2.1047e+01, -7.1931e+00,\n",
              "          1.1280e+01,  9.8282e+00,  1.0032e+01,  1.2307e+01,  2.1966e-01,\n",
              "          1.9684e+01, -9.1890e+00,  5.5153e+00, -3.4112e+00,  9.3539e+00,\n",
              "          3.8272e+00,  9.7007e+00, -9.7206e+00,  7.0472e+00,  5.9204e+00,\n",
              "          1.0605e+01,  6.1211e+00, -5.6748e+00, -2.4339e+00,  1.0971e+01,\n",
              "         -3.8866e+00, -7.1369e+00],\n",
              "        [-1.2162e+00, -2.0989e+00, -1.0151e+01, -3.2966e+00,  1.5090e+00,\n",
              "         -1.0855e+00, -4.0246e+00, -4.7903e-01,  5.3732e+00, -1.0497e+00,\n",
              "          1.3822e+01, -1.7629e+01,  3.8197e+00, -3.8497e+00,  5.5095e-01,\n",
              "         -6.0285e+00,  7.6786e-01,  7.2800e-02,  9.1152e+00,  6.4979e-02,\n",
              "          2.8013e+00, -7.3542e+00, -3.4501e+00, -1.2316e+01, -6.8039e+00,\n",
              "          6.2118e+00,  6.6022e+00],\n",
              "        [-1.0779e+00,  5.6241e+00, -8.7834e+00, -1.0851e+00, -1.6902e+00,\n",
              "          2.1776e+00, -1.2576e+01,  6.0073e+00, -3.2603e+00, -1.3499e+01,\n",
              "          9.4666e+00,  4.8480e+00, -1.6140e+01, -4.5044e+00,  5.7854e+00,\n",
              "         -3.4035e+00, -1.4951e+00, -2.0456e+00,  8.4289e+00, -9.3169e+00,\n",
              "          5.0676e+00,  2.2225e+00, -3.5815e+00, -3.6759e+00, -6.3380e+00,\n",
              "          6.4591e+00,  3.9632e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "8N5W7Fdi5_Tc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = counts / counts.sum(1, keepdims=True)"
      ],
      "metadata": {
        "id": "B7kCmYNT6BdU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob.shape"
      ],
      "metadata": {
        "id": "01fgqyUC6IIs",
        "outputId": "a38bb768-a0ee-4513-828a-91cbdfef26ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Every row sums up to 1\n",
        "prob[0].sum()"
      ],
      "metadata": {
        "id": "c1WNYXOE6LqZ",
        "outputId": "2a3c5650-1588-4c68-f692-a92e52a82bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "x81oLWf96TXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index into the rows of prob and from each row pluck out the probability assigned to the correct character\n",
        "# iterator\n",
        "torch.arange(32)"
      ],
      "metadata": {
        "id": "FBo_o7cS6R3f",
        "outputId": "141f214b-6bf4-4a5e-b5b0-31119866de3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices of correct characters\n",
        "Y"
      ],
      "metadata": {
        "id": "NJFdfUAc6pns",
        "outputId": "d3bc4b1e-b686-482b-ec34-052af98313e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[torch.arange(32), Y]"
      ],
      "metadata": {
        "id": "UP1EBDbj6jZJ",
        "outputId": "2d698f0d-d61a-498d-a945-a11cd00e191e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.6747e-05, 3.7659e-05, 4.9466e-12, 1.2362e-04, 6.9568e-12, 9.2345e-11,\n",
              "        1.4742e-12, 3.1718e-06, 3.2212e-12, 1.8734e-12, 1.0331e-05, 3.5257e-08,\n",
              "        2.1641e-06, 2.1563e-07, 4.6641e-07, 1.1791e-13, 1.7204e-09, 8.8416e-03,\n",
              "        1.6172e-08, 1.6094e-10, 4.0914e-08, 1.3155e-06, 6.8367e-06, 1.0493e-03,\n",
              "        1.7483e-07, 9.9944e-05, 6.3317e-08, 2.5939e-07, 1.1865e-09, 7.1756e-10,\n",
              "        1.2057e-07, 1.7494e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is what we need to minimize to get the correct character\n",
        "loss = - prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "id": "psRnrBcm65E7",
        "outputId": "6f586896-3f62-4f76-930f-1899444390b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8338)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full flow"
      ],
      "metadata": {
        "id": "oSumqSqu7GRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "Kf-fB0hD7JoH",
        "outputId": "6fec5390-056a-45b5-94f1-4a81e4aa7561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "W1 = torch.randn((6, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "IhDu42ee7Nnm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of params\n",
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "id": "kyr2AHjS79ON",
        "outputId": "71add3c5-1d15-4ba5-f547-e9aa025ed3ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 1: embedding\n",
        "emb = C[X] #(32, 3, 2) 32 examples with 3 chars each and 2 dimensions to them\n",
        "# Layer 2: hidden layer\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # outputs (32, 100)\n",
        "# Layer 3: output\n",
        "logits = h @ W2 + b2\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims=True)\n",
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "id": "FULu7OOr8Fr4",
        "outputId": "072c5308-2e46-433e-c9bf-790282904545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7697)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the loss can be done directly from pytorch\n",
        "F.cross_entropy(logits, Y)"
      ],
      "metadata": {
        "id": "R0BDIQ0W9O03",
        "outputId": "a5e094c1-b281-4968-9292-ef8e58a874de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7697)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 1: embedding\n",
        "emb = C[X] #(32, 3, 2) 32 examples with 3 chars each and 2 dimensions to them\n",
        "# Layer 2: hidden layer\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # outputs (32, 100)\n",
        "# Layer 3: output\n",
        "logits = h @ W2 + b2\n",
        "#counts = logits.exp()\n",
        "#prob = counts / counts.sum(1, keepdims=True)\n",
        "#loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "id": "cEBaSmSe9Xh3",
        "outputId": "39b5d6f0-8850-4aa1-f769-de3327082b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7697)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many reasons to prefer F.cross_entropy over own implementation\n",
        "1. F.cross_entropy won't create all the intermediate tensors. Pytorch uses fused kernels to more efficienctly calculate\n",
        "The backwards pass would be much more efficient\n",
        "2. F.cross_entropy is more numerically well-behaved - example below"
      ],
      "metadata": {
        "id": "bCXtpghN9cRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.tensor([-2, -3, 0, 5])\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum()\n",
        "probs"
      ],
      "metadata": {
        "id": "H2k7jorw9_gt",
        "outputId": "5c16f589-9bf6-4a74-af91-a0557941477b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.0466e-04, 3.3281e-04, 6.6846e-03, 9.9208e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed we have more extreme numbers\n",
        "logits = torch.tensor([-100, -3, 0, 5])\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum()\n",
        "probs"
      ],
      "metadata": {
        "id": "wh5G6eVc-MdK",
        "outputId": "86d7771c-2373-42d4-eeac-aac9e78f1835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 3.3311e-04, 6.6906e-03, 9.9298e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed we have more extreme positive\n",
        "logits = torch.tensor([-100, -3, 0, 100])\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum()\n",
        "probs"
      ],
      "metadata": {
        "id": "TEKlVCZQ-SIl",
        "outputId": "9bc9f58c-14f8-4ba0-e488-ed9f42d48ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., nan])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "id": "aTxl6TsL-XFZ",
        "outputId": "79d1f7ff-d4e1-4b0d-c1f0-5080c2c15a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.7835e-44, 4.9787e-02, 1.0000e+00,        inf])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you pass a very positive number to .exp() we run out of range in our floating point number that represents the count(e to the power of 100).\n",
        "\n",
        "You can offset logits by any arbitrary number you want and get the same result.\n",
        "F.cross_entropy calculates the max value in the logits and subtracts it"
      ],
      "metadata": {
        "id": "vSbDJkCh-Zci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "slLHI0iX_ZzJ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(100):\n",
        "    # forward pass\n",
        "    emb = C[X]\n",
        "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    #print(loss.item())\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.1 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "H20ptH-Z-YhU",
        "outputId": "bf386c73-9814-4612-954e-4e358255829d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.31377431750297546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're achieving extremely low loss - overfitting. We are fitting 32 examples using almost 4k parameters - very easy to make the NN fit them.\n",
        "We can't achieve 0 - ... is supposed to predict 5 different first letters"
      ],
      "metadata": {
        "id": "_jMr6p3-_swI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(1)"
      ],
      "metadata": {
        "id": "sE0rCMNg_CPV",
        "outputId": "661cfc4a-dde0-4635-fb22-bab1f7c52e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([11.4639, 13.4778, 19.0661, 17.9120, 13.2064, 11.4639, 13.2552, 11.8626,\n",
              "        13.6934, 15.6432, 12.8634, 17.9044, 11.4639, 13.2158, 14.3344, 17.2696,\n",
              "        11.4639, 14.0626, 11.7470, 13.5321, 15.9663, 12.5515,  8.1474,  8.1505,\n",
              "        14.0189, 11.4639, 13.5286, 13.8694, 11.3024, 14.4007, 15.8964, 12.3963],\n",
              "       grad_fn=<MaxBackward0>),\n",
              "indices=tensor([ 1, 13, 13,  1,  0,  1, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  1, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0,  1, 15, 16,  8,  9,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run on full dataset"
      ],
      "metadata": {
        "id": "XOQHmNoGAOzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "block_size = 3 #context length - how many input chars to predict next\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words:\n",
        "  #print(w)\n",
        "  context = [0] * block_size\n",
        "  #print(f'Context: {context}')\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "    context = context[1:] + [ix] #crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "n-EMZKT1ARN_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "id": "CdC0kIPUAd9f",
        "outputId": "f60f28eb-e9fa-4d57-e86d-88dd7ac8b173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "W1 = torch.randn((6, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "ISIGHFeiAjXN"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of params\n",
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "id": "6TTgUGJ2A6Uv",
        "outputId": "07ed0e33-7835-4769-fb55-cca8d0623f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "BpzYx1VzAvJb"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    # forward pass\n",
        "    emb = C[X]\n",
        "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    print(loss.item())\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    #update\n",
        "    for p in parameters:\n",
        "        p.data += -0.1 * p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "w2Tie6FNAvsH",
        "outputId": "18798235-f1c5-4ed7-e469-e8c358676c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.709586143493652\n",
            "10.407632827758789\n",
            "10.127808570861816\n",
            "9.864365577697754\n",
            "9.614503860473633\n",
            "9.376440048217773\n",
            "9.148944854736328\n",
            "8.931111335754395\n",
            "8.7222318649292\n",
            "8.521750450134277\n",
            "8.521750450134277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice forward and backwards passes on batches of the data, not the full dataset"
      ],
      "metadata": {
        "id": "sR6xEYzPBFjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0, 5, (32,))"
      ],
      "metadata": {
        "id": "TAnzpm7MBKkd",
        "outputId": "119f3fd4-ba98-461f-bb2b-4f88d718f085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 3, 2, 1, 3, 3, 2, 0, 3, 3, 3, 4, 2, 2, 1, 3, 0, 0, 4, 2, 2, 1,\n",
              "        2, 2, 3, 3, 1, 0, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    }
  ]
}