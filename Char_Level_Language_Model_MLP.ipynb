{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martush/martush_notebooks/blob/develop/Char_Level_Language_Model_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AvUjvsYPlX2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "22EnvimylhXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ea459b-21d6-4e5d-ad08-f72a42794270"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('gdrive/My Drive/names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2754BNSrt63H",
        "outputId": "e29057f2-7ec6-4d39-9bc9-3413eb345e55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrdUxHrt9Cs",
        "outputId": "ef435c24-3c43-4c17-dfef-f19361e486e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build vocabulary of all chars and mapping to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYfSxHRyt-r5",
        "outputId": "97c6af2a-aa0f-47f6-8bc3-21f6a2b3b924"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "block_size = 3 #context length - how many input chars to predict next\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  print(f'Context: {context}')\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "    context = context[1:] + [ix] #crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNvQZW0ugw0",
        "outputId": "a17440b6-738b-4533-d6c6-980fdce8dbaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "Context: [0, 0, 0]\n",
            "... ----> e\n",
            "..e ----> m\n",
            ".em ----> m\n",
            "emm ----> a\n",
            "mma ----> .\n",
            "olivia\n",
            "Context: [0, 0, 0]\n",
            "... ----> o\n",
            "..o ----> l\n",
            ".ol ----> i\n",
            "oli ----> v\n",
            "liv ----> i\n",
            "ivi ----> a\n",
            "via ----> .\n",
            "ava\n",
            "Context: [0, 0, 0]\n",
            "... ----> a\n",
            "..a ----> v\n",
            ".av ----> a\n",
            "ava ----> .\n",
            "isabella\n",
            "Context: [0, 0, 0]\n",
            "... ----> i\n",
            "..i ----> s\n",
            ".is ----> a\n",
            "isa ----> b\n",
            "sab ----> e\n",
            "abe ----> l\n",
            "bel ----> l\n",
            "ell ----> a\n",
            "lla ----> .\n",
            "sophia\n",
            "Context: [0, 0, 0]\n",
            "... ----> s\n",
            "..s ----> o\n",
            ".so ----> p\n",
            "sop ----> h\n",
            "oph ----> i\n",
            "phi ----> a\n",
            "hia ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8kFSxeUwDmf",
        "outputId": "f7c02963-79e7-4f2a-e0d4-0a350e55e128"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueN4rrJMxmZL",
        "outputId": "0d5efdd1-c24c-47f0-8800-4b1b6f81d884"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to create the lookup table. In the reference paper they have 17,000 words crammed into 30 dimensions. We only have 27 characters and we can start  with only 2 dimensions."
      ],
      "metadata": {
        "id": "3KZfkXa2xxr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2))"
      ],
      "metadata": {
        "id": "GK1CPdV4yUtC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check a single embedding\n",
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqQzGYWtyGIH",
        "outputId": "526bb6ae-d9ad-4cc8-a2a5-bfa29fda7098"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0899,  2.5120])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5,6,7,7,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mimn1w_-vAip",
        "outputId": "3cba9c41-31ee-4581-aed3-adbba3bbeb71"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0899,  2.5120],\n",
              "        [ 0.3969,  0.3909],\n",
              "        [ 1.0112,  1.2152],\n",
              "        [ 1.0112,  1.2152],\n",
              "        [ 1.0112,  1.2152]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also index with multiple dimension\n",
        "C[X]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljbHvyg9vVne",
        "outputId": "d7f158e4-0092-4aa6-d10b-67d2d824b385"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-0.0899,  2.5120]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-0.0899,  2.5120],\n",
              "         [-0.7480, -0.5429]],\n",
              "\n",
              "        [[-0.0899,  2.5120],\n",
              "         [-0.7480, -0.5429],\n",
              "         [-0.7480, -0.5429]],\n",
              "\n",
              "        [[-0.7480, -0.5429],\n",
              "         [-0.7480, -0.5429],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-0.0382,  1.5695]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-0.0382,  1.5695],\n",
              "         [ 1.7933,  1.0435]],\n",
              "\n",
              "        [[-0.0382,  1.5695],\n",
              "         [ 1.7933,  1.0435],\n",
              "         [ 1.4301, -0.9535]],\n",
              "\n",
              "        [[ 1.7933,  1.0435],\n",
              "         [ 1.4301, -0.9535],\n",
              "         [-0.0168,  0.4928]],\n",
              "\n",
              "        [[ 1.4301, -0.9535],\n",
              "         [-0.0168,  0.4928],\n",
              "         [ 1.4301, -0.9535]],\n",
              "\n",
              "        [[-0.0168,  0.4928],\n",
              "         [ 1.4301, -0.9535],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [ 0.0502,  0.1692],\n",
              "         [-0.0168,  0.4928]],\n",
              "\n",
              "        [[ 0.0502,  0.1692],\n",
              "         [-0.0168,  0.4928],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [ 1.4301, -0.9535]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [ 1.4301, -0.9535],\n",
              "         [-0.4193, -0.7521]],\n",
              "\n",
              "        [[ 1.4301, -0.9535],\n",
              "         [-0.4193, -0.7521],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-0.4193, -0.7521],\n",
              "         [ 0.0502,  0.1692],\n",
              "         [ 1.0276,  0.2210]],\n",
              "\n",
              "        [[ 0.0502,  0.1692],\n",
              "         [ 1.0276,  0.2210],\n",
              "         [-0.0899,  2.5120]],\n",
              "\n",
              "        [[ 1.0276,  0.2210],\n",
              "         [-0.0899,  2.5120],\n",
              "         [ 1.7933,  1.0435]],\n",
              "\n",
              "        [[-0.0899,  2.5120],\n",
              "         [ 1.7933,  1.0435],\n",
              "         [ 1.7933,  1.0435]],\n",
              "\n",
              "        [[ 1.7933,  1.0435],\n",
              "         [ 1.7933,  1.0435],\n",
              "         [ 0.0502,  0.1692]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-1.5427,  0.5617],\n",
              "         [-0.4193, -0.7521]],\n",
              "\n",
              "        [[-1.5427,  0.5617],\n",
              "         [-0.4193, -0.7521],\n",
              "         [-0.0382,  1.5695]],\n",
              "\n",
              "        [[-0.4193, -0.7521],\n",
              "         [-0.0382,  1.5695],\n",
              "         [-1.3716,  0.4467]],\n",
              "\n",
              "        [[-0.0382,  1.5695],\n",
              "         [-1.3716,  0.4467],\n",
              "         [ 0.0750, -1.5654]],\n",
              "\n",
              "        [[-1.3716,  0.4467],\n",
              "         [ 0.0750, -1.5654],\n",
              "         [ 1.4301, -0.9535]],\n",
              "\n",
              "        [[ 0.0750, -1.5654],\n",
              "         [ 1.4301, -0.9535],\n",
              "         [ 0.0502,  0.1692]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spElmstEvfav",
        "outputId": "26a5ed6e-24a0-45cc-a7d4-6c07d1df6328"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[13,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5m2N0WtvuNn",
        "outputId": "dd98051d-9d16-4020-c86e-aaaf2a0d7629"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X][13,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2N0w4dSvxVE",
        "outputId": "7bdaaee2-5e41-4d07-df4d-180db74aa427"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0502, 0.1692])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljz_e6jGvuQF",
        "outputId": "0e3a64ae-1b2c-4ead-e096-b1033c9902ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0502, 0.1692])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = F.one_hot(torch.tensor(5), num_classes=27)\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTBFQ2d8yCut",
        "outputId": "f383c491-daeb-4b97-8570-9f507852182f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot are int64 and C is float - pytorch doesn't know how to multiply them\n",
        "encoded @ C"
      ],
      "metadata": {
        "id": "khbczIlCyl3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identical output\n",
        "encoded.float() @ C"
      ],
      "metadata": {
        "id": "zEH5CZ6oy9BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 approaches with identical results. Will simply index (C[5]) since much faster"
      ],
      "metadata": {
        "id": "8aslyUHWzUkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch indexing is quite flexible and powerful\n",
        "# We have a X with size [32, 3] which we want to embed\n",
        "# We can index 3 things at the same time\n",
        "C[[5,6,7]]"
      ],
      "metadata": {
        "id": "tmuYmPYUza5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dqcoixwwoxu",
        "outputId": "ea1ef8cc-3a5d-488e-cf0d-a5f549a3a9fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the hidden layer"
      ],
      "metadata": {
        "id": "nNIhIWNxw5wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.Size([32, 3, 2])\n",
        "# Inputs: 3 x 2 - 3 two-dimensional embeddings\n",
        "# Outputs we pick - pick 100 neurons\n",
        "W1 = torch.randn((6, 100))\n",
        "# biases - initialized randomly, need 100 of them\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "XmhOPsZ8wo17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normally we'd take the input and multiply it by the weights\n",
        "emb @ W1 + b1\n",
        "# Problem is the embeddings are stacked up in the dimensions in the input tensor - 32 x 3 x 1 can't multiply by 6 x 100\n"
      ],
      "metadata": {
        "id": "tQQDIXuqwo7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}